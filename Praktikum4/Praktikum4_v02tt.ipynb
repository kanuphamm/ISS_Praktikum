{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "eafc4fcf-0a48-41c8-a92e-e77575c87916",
   "metadata": {},
   "source": [
    "# Praktikum Intelligente Sensortechnik 4\n",
    "Tim Tiedemann, Thomas Lehmann, Tobias De Gasparis\n",
    "\n",
    "Version 11.05.2023"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cf12a59-7e4b-4e09-89f9-447fff74170b",
   "metadata": {},
   "source": [
    "# Einfache intelligente Sensoren und Datenvorverarbeitung\n",
    "Im Praktikum 4 geht es um die Verarbeitung hochdimensionaler Daten bzw. die Klassifikation der Daten.\n",
    "\n",
    "Lesen Sie sich die Aufgaben gut durch. Sollten Sie eine Aufgabe nicht lösen können, so beschreiben Sie zumindest, wie weit Sie gekommen sind und auf welche Weise Sie vorgegangen sind.\n",
    "\n",
    "Beachten Sie auf der methodischen Seite, dass die Schritte der Datenerhebung, der Datenauswertung und der Kommentierung des Ergebnisses ausgeführt werden. Alle Diagramme sind korrekt zu beschriften.\n",
    "\n",
    "Die Aufgaben sind direkt hier als Protokoll zu bearbeiten. Das abgegebene Notebook soll ausführbar sein. Daneben ist der PDF-Export des Notebook mit abzugeben."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0537730a-2b4a-4a61-89f5-8ff590f6dc7a",
   "metadata": {},
   "source": [
    "Autoren des Protokolls: Khanh Nhu Pham, Berivan Elmas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4afe8f3-c64f-4c97-b006-4c88cab5638f",
   "metadata": {},
   "source": [
    "# Hintergrund\n",
    "Intelligente Sensoren sollen nicht nur Daten erfassen, sondern direkt eine Klassifikation mit Informationen auf abstrakterer Ebene aus der Umwelt liefern. Beispielsweise soll eine Geste oder Gegenstände erkannt werden und diese Information über die Schnittstelle zu weiteren Systemkomponenten bereitgestellt werden. In diesem Praktikum wird die Leistungsfähigkeit der Klassifikation einfacher Algorithmen des nicht-überwachten Machine Learnings für diese Aufgabe untersucht."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de19e183-f52a-42cb-adce-ee835c36cead",
   "metadata": {},
   "source": [
    "# Vorbereitungsaufgaben\n",
    "## Sensoren mit hochdimensionaler Ausgabe von Daten\n",
    "Besorgen Sie sich Informationen zu den folgenden Sensoren: \n",
    "\n",
    "- Hokuyo URG-04LX-UG01\n",
    "- Hokuyo UTM-30LX-EW\n",
    "- Velodyne VLP-16\n",
    "\n",
    "Um was für einen Sensor handelt es sich jeweils und welches Messprinzip wird verwendet? Was wird gemessen? Was sind hier der Messbereich, die Auflösung und die Sample-/Messrate?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3568755-8972-40b1-a648-825c9496c3e7",
   "metadata": {},
   "source": [
    "- Hokuyo URG-04LX-UG01\n",
    "    - Umgebungsscanner über Infrarot, Phasenverschiebung\n",
    "    - Messbereich: 20mm-4000mm\n",
    "    - Die Messrate beträgt 10Hz\n",
    "    - Die Auflösung beträgt 1mm\n",
    "    \n",
    "- Hokuyo UTM-30LX-EW\n",
    "    - Umgebungsscanner, Triangulationsprinzip\n",
    "    - Messbereich: 0.1m-30m\n",
    "    - Die Messrate beträgt 40Hz\n",
    "    - Die Auflösung beträgt 1mm\n",
    "    \n",
    "- Velodyne VLP-16\n",
    "    - Distanzmessung über Infrarot, TOF\n",
    "    - Messbereich:100m\n",
    "    - Die Samplerate beträgt 18.08 kHz pro IR-Detektor\n",
    "    - Die Winkelauflösung beträgt horizontal 0.1°-0.4° und vertikal 2.0°"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3f8f7ad-66f6-457d-94e2-0dc5c5c00cad",
   "metadata": {},
   "source": [
    "Über welche Schnittstelle(n) können die Messdaten ausgegeben werden? Wie werden jeweils Betriebsspannung und Datenleitungen angeschlossen?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e65eea1c-84a7-495b-967a-c980d0b04ffe",
   "metadata": {},
   "source": [
    "- Hokuyo URG-04LX-UG01 USB\n",
    "- Hokuyo UTM-30LX-EW Datenblatt Abschnitt 6.1 S.4\n",
    "- Velodyne VLP-16 User Manual Abschnitt 2.1 S.18"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3a13536-be2f-45f4-a51e-adcec495b336",
   "metadata": {},
   "source": [
    "# Im Labor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb6876b9-d62b-4f2e-8963-e48e0cedc2e2",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Objektidentifikation in Daten von Laserscannern\n",
    "Mit LiDARs vom Typ Hokuyo URG-04LX-UG01 sollen Sie die Umgebung der Sensoren erfassen und mittels Clustering-Algorithmus auswerten. Sie sollen untersuchen, ob die Objekte der Umgebung durch den Cluster-Algorithmus gefunden werden."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f83dfd96-912e-454d-9e64-e51c96e67185",
   "metadata": {},
   "source": [
    "### Datenerfassung"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad956e31-648e-4968-ad7f-47e22952feb4",
   "metadata": {
    "tags": []
   },
   "source": [
    "Verwenden Sie in Absprache mit dem Laborbetreuer einen Sensor vom Typ Hokuyo URG-04LX-UG01 für die Datenerfassung. Wie werden Daten erfasst und wie können sie auf diese zugreifen?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdf7150b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1d39109e-5181-464a-8596-17f542e18e18",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1ed41f47-d7ce-481e-8d49-4242769d2456",
   "metadata": {},
   "source": [
    "Sammeln Sie Daten von einem Scan und versuchen Sie die Daten in einer zweidimensionalen Karte darzustellen. Können Sie Objekte in der Umgebung identifizieren?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb034f08-6329-4a68-9ff4-5205befa7d49",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f3b2fe08-bbb6-479d-838f-92537c7ca1de",
   "metadata": {},
   "source": [
    "Nehmen Sie von zwei LiDARs einen Scan auf. Gehen Sie davon aus, dass einer der Laserscanner im Ursprung eines karthesischen Koordinatensystems (Weltkoordinatensystem) angebracht ist und mit der Mittelachse genau in Richtung der y-Achse ausgerichtet ist. Fügen Sie die Daten des zweiten Laserscanners mittels geeigneter Rotation und Translation (Argumente experimentell bestimmen) in das Weltkoordinatensystem ein, so dass sich ein Gesamtbild in der Karte ergibt. Geben Sie die nötige Rotationsmatrix und den Translationsvektor an bzw. bauen Sie Ihre Datentransformation so auf, dass mit einer Rotationsmatrix und einem Translationsvektor gearbeitet wird.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbd8155b-e2cb-40e4-bed1-70d477581509",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "785834b0-dafa-4e01-a1f3-2afa14bffdd3",
   "metadata": {},
   "source": [
    "### Clustering der Daten"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b25dd8c-833f-41a9-981b-6e761a4f329f",
   "metadata": {},
   "source": [
    "Führen Sie nun ein Clustering mittels DBSCAN aus der scikit-learn-Bibliothek auf den gesammelten LiDAR-Daten von einem Sensor durch. Verwenden Sie evtl. erstmal nur einen Teil, z.B. die ersten 100 Sensordimensionen (Entfernungswerte). Finden Sie geeignete Parameter “min_samples” und “eps”. Stellen  Sie die Cluster-Zuordnung der Punkte in der Karte dar. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7815ed17-724e-44ab-889b-e452c45d397c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "143bec0a-8543-4a3d-bba4-72ab735d6bbb",
   "metadata": {},
   "source": [
    "Wieviele Cluster werden in Ihrem Datensatz identifiziert? Welche Objekte könnten es sein?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c32e2e95-7923-489d-b03f-1c3a3836614e",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d8fc883f-e119-4921-88b6-46e2816d46da",
   "metadata": {},
   "source": [
    "Sollte im LiDAR-Datensatz eine Standardisierung durchgeführt werden? Was spricht dafür und was dagegen? Beachten Sie die Arbeitsweise von DBSCAN."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4559eb5d-9135-4155-b231-78636304b8c7",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "90eb9ecc-ff2e-46e8-8945-de4d3f7e8b4c",
   "metadata": {},
   "source": [
    "Können Sie eine Daumenregel für die Wahl der Parameter von DBSCAN ableiten, so dass Objekte in der Umgebung als getrennte Objekte erkannt werden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b94919f-aa49-4426-b5a7-b694d326a9d5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "28d84266-6f65-4b82-b379-61048e92f82b",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Bewegungserkennung\n",
    "Aus den Daten der Sensoren des Nucleo-Moduls soll nun eine Bewegung identifiziert werden."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0e5f84d-849d-4dca-b504-b9cc8ccd354c",
   "metadata": {},
   "source": [
    "### Datenerfassung\n",
    "\n",
    "Verwenden Sie im folgenden das IKS01A3-Board und Ihr Programm, wie Sie es zum Sammeln der 12-dimensionalen 1024-Sample Datensätzen verwendet haben.\n",
    "\n",
    "Nehmen Sie einen Datensatz auf, in dem das Modul zunächst still in einer Postion (und Ausrichtung) steht, dann eine Bewegung durchgeführt wird (Translation und dann Rotation) und das Modul dann still in einer anderen Position (und Ausrichtung) steht. Dokumentieren (Skizze) Sie die Bewegung! (Empfehlung: Filmen Sie die Bewegung, damit Sie ggf. einige Punkte in den Datensätzen bei der Auswertung besser einer Bewegung zuordnen können.)\n",
    "\n",
    "### Auswertung\n",
    "Stellen Sie sich diesen Datensatz graphisch als Plot (2D/3D) dar und prüfen Sie, ob die verschiedenen Phasen zu erkennen sind. Zeigen Sie hier einen geeigneten Plot/Ausschnitt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27144c36-96c0-4dd3-b6ab-212297e276c0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f090954d-eeb0-4f78-9ecd-ac205a8d49a7",
   "metadata": {},
   "source": [
    "Versuchen Sie mittels Clustering-Algorithmus (k-Means und DBSCAN) die Bewegungen/Bewegungsabschnitte in den Daten zu identifizieren. Welches Verfahren kann wie gut die Bewegung/Bewegungsabschnitte bei welchen Parametern identifizieren? Welche Normierung/Skalierung war sinnvoll? Ist eine Reduktion mit PCA sinnvoll? Stellen Sie die Ergebnisse des Clusterings ggf. auch in Plots über die Zeit dar.\n",
    "\n",
    "Fügen Sie hier Ihre Analyse kommentiert ein."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2d80827-b979-44df-afd0-a02506641278",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "87b480c9-1c93-4354-8989-e7c7892c5ad6",
   "metadata": {},
   "source": [
    "### Sensorsystem\n",
    "Wenn Sie nun das Sensorboard zusammen mit den Cluster-Algorithmen als Sensorsystem betrachten, welche Information(en) könnte die Schnittstelle des Sensorsystems als Ergebnis der Klassifikation bereitstellen? "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02b02448",
   "metadata": {},
   "source": [
    "- Wenn die Klassifizierungen bereits bei der Ausgabe der Sensordaten angewendet werden, dann werden einzelne Datenpunkte gesammelt und als eine spezifische Bewegung interpretiert/ausgegeben --> ordnet Datenpunkte und Folgeaufnahmen einer Bewegung zu"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
